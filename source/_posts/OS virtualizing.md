---
title: Operating System
date: 2021-07-09 21:59:32
tags:
- 操作系统
category: 读书笔记
---

> 虚拟化

<!-- more -->

# 进程(process)

> 操作系统提供的最基本的抽象

- 进程就是运行中的程序

程序本身是没有生命周期的，它只是存在磁盘上的一些指令或者静态数据，操作系统让这些字节运行起来发挥作用。

一个操作系统可能有上百个进程在同时运行，但只有少量物理CPU可用，操作系统通过虚拟化CPU来提供无数个CPU的假象，也就是时分共享技术。

- 时分共享:通过让一个进程只运行一个时间片，然后切换到其它进程。（这会让每个进程运行慢一些）

> 与之相对的有空分共享，也就是资源在空间上划分，磁盘空间就是这样。

进程独享内存和CPU，当然都是虚拟的

## 进程状态

- 运行(running)：进程正在处理利器上运行，执行命令。
- 就绪(ready):：进程已经准备好运行但是由于某种原因，操作系统选择不在此时运行。
- 阻塞(blocked)：进程执行了某种操作，直到发生其他时间才会准备运行。比如磁盘IO或者网络IO时

<img src="/Users/c1eye/Library/Application Support/typora-user-images/image-20210709235014994.png" alt="image-20210709235014994" style="zoom:50%;" />

## 进程的数据结构

当一个进程停止时，它的**寄存器里的信息**将被保存到内存上的一个位置，当操作系统恢复该进程时，将这些值放回寄存器中就可以恢复该进程。这也成为**上下文切换**。

> xv6内核中的上下文信息 

![image-20210709235940006](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210709235940.png)

>  如何高效可控的虚拟化CPU?

## 受限直接执行LDE

**进程如何执行受限制的操作？比如磁盘IO**

- 用户模式和内核模式
- 陷阱表

### 进程间切换



## 进程调度

> 系统调度程序采用的上层策略

### 性能指标

**周转时间**：任务完成时间-任务到达时间

**响应时间**：首次运行时间-任务到达时间

### 先进先出FIFO

字如其名，先到先执行，也被称为先到先服务FCFS。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210712222821.png" alt="image-20210712222821516" style="zoom:50%;" />

这种模式易于实现，但是如果先到达的任务耗时长后到达的任务就不得不等待较长时间，导致平均周转时间较高。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210712222836.png" alt="image-20210712222835978" style="zoom:50%;" />

- 这个问题被称为「护航效应」(convoy effect),即一些耗时较少的资源消费者被排在重量级的资源消费者之后。

### 最短任务优先SJF

先执行运行最短的任务，然后是次短的任务，如此下去。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210712223645.png" alt="image-20210712223644965" style="zoom:50%;" />

还是有些问题，如果A先到达，而B，C在稍后到达，B，C还是要等待A先完成，平均周转时间还是不低。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210712223810.png" alt="image-20210712223810696" style="zoom:50%;" />

### 最短完成时间优先STCF（抢占式最短作业优先PSJF）

在上面的SJF中，由于调度不是抢占式的（任务一旦开始必须按完成再进行其他任务），所以会有些问题。而现代操作系统几乎都是抢占式的。介于时钟中断和上下文切换机制，当B，C到达时，调度程序可以抢占工作A开始别的工作，稍后执行A。

这种模式下在新的工作到达时会确定新工作和剩余工作谁的时间少，先执行时间少的。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210712225613.png" alt="image-20210712225613267" style="zoom:50%;" />

> 上面的几种调度中对于响应时间不太友好，而下面介绍一些对响应时间敏感的调度

### 轮转RR

RR在一个时间片内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束。反复执行直到完成所有任务。

需要注意的是，时间片长度必须是时钟周期的倍数。而且上下文切换是有成本的，而且会影响整体性能，所以需要权衡时间片的长度，使其足够长可以**摊销**上下文切换成本，而又不会使系统不及时响应。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210712230224.png" alt="image-20210712230224583" style="zoom:50%;" />

> 摊销是指设置恰当的时间片使切换上下文的时间占比较小

但是RR在周转时间上就比较可怕了。

一般来说，公平的调度往往周转时间都不会太好，而不公平的调度又会以响应时间为代价。这就是不可兼得的两个事物吧...

### 结合I/O

在进行IO操作时CPU会空闲出来，此时就可以决定进行其他的工作。进行调度时可能需要考虑IO结束后继续进行现在的工作还是原来的工作。

具体点说，如果两项工作A，B的CPU耗时一样，但是A有IO操作，一种常见的方法是将A分为多个子工作，并将子工作视为独立的工作，这时进行抢占式调度，来尽可能重叠使用资源。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210712233818.png" alt="image-20210712233818627" style="zoom:50%;" />

### 无法预知

实际上，真实情况下我们的操作系统很难得知每个作业的长度。之后的章节将介绍这个问题的解决方案。



------

> 作为读书笔记感觉结构不是很好，打算换个结构，以此为界

# 第八章 调度:多级反馈队列MLFQ

MLFQ需要解决两方面问题

- 优化周转时间（SJF等需要工作的运行时间来优化，但我们对工作的运行时间并不清楚）
- 降低响应时间（RR的响应时间不错，但是周转时间很糟糕）

## MLFQ基本规则

> 尽管实现不尽相同，但是方法大多类似

MLFQ中有许多的独立的队列，每个队列有不同的优先级，在任一时刻，一个工作只能存在于一个队列中。MLFQ总是优先执行较高优先级的工作。

对于一个队列中的工作采用RR调度。由此得到两个规则

![image-20210713211155472](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210713211155.png)

对于每个工作，MLFQ会观察工作的行为来预测它的行为，进而调整工作的优先级。

既有运行时间很短频繁放弃CPU的交互性工作，也有需要很多CPU时间，响应时间不重要的计算密集型工作，由此调整优先级算法如下：

![image-20210713211650502](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210713211650.png)

如下图所示，一个长工作的优先级不断降低。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210713211758.png" alt="image-20210713211758656" style="zoom:50%;" />

**可以看到这个算法的主要目标：**

假设工作是短工作，赋予最高优先级。如果是短工作，很快就会执行完毕，否则🏆慢慢移入低优先级队列，而这时工作也被认为是长工作了。

**如果有I/O呢？**

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210713212439.png" alt="image-20210713212439700" style="zoom:50%;" />

由于在时间片用完之前归还CPU不会被降级，IO操作较多的工作能保持在较高优先级执行。

### 当前规则的问题

- 长工作可能永远不会被执行
- 如果某个程序故意在时间片用完之前调用IO操作，可以维持在高优先级，操作的当几乎可以独占CPU
- 一些长工作会有些交互操作，而它们并不能享受高优先级

>一个简单的思路是周期性的提升优先级

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210713213158.png" alt="image-20210713213158708" style="zoom:150%;" />

这样解决了长工作的饿死问题和长工作的交互部分优先级太低

下图可以看到没有提升优先级的左面的长工作在两个短工作到达后被饿死。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210713213502.png" alt="image-20210713213502813" style="zoom:50%;" />

>  当然，这又带来了新的问题，S的值要如何设置？

太高会导致长工作饥饿，太短会挤占交互工作的CPU时间。

### 更好的计时方式

现在还有个问题，如何阻止跳读程序被愚弄？也就是在时间片结束前发起IO来占用CPU的行为。

![image-20210713214213771](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210713214213.png)

我们重写一下规则4，现在调度程序记录每一层中消耗的总时间而不是每次重新计时。

![image-20210713214438114](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210713214438.png)

### MLFQ调优及其他问题

MLFQ一般都支持更改队列数目和时间片，高级队列往往有较短的时间片，低级则较长。

- 有些MLFQ基于数学公式和CPU占用来计算优先级，甚至没用到表
- 不同系统提供的MLFQ特征不同，RTFM

## 总结

![image-20210713214906366](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210713214906.png)

## 作业

# 第九章 调度：比例份额

> 调度程序的最终目标是确保每个工作获得一定比例的CPU时间，而不是优化周转时间和响应时间

## 彩票调度

彩票调度是一个现代的优秀比例份额调度程序，它基于一个基本概念

- 彩票数代表了进程战友某个资源的份额

也就是说一个进程拥有的彩票数占总彩票数的百分比就是它占有的资源的份额。

- 通过不断定时抽取彩票，进程从概率上获得份额比例，中奖时执行

![image-20210714203315576](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210714203315.png)

> 彩票调度利用了随机性，随机通常很快也不需要记录太多状态

### 彩票机制

- 彩票货币：允许用户将全局的彩票兑换成私有的彩票来分发给自己的工作，操作系统在抽奖时会兑换回来
- 彩票转让：一个进程可以临时将自己的彩票交给另一个进程
- 彩票通胀：在互相信任的环境中，进程可以增加或减少自身的彩票数，不需要告知其他进程

## 步长调度

> 随机的调度有时不能产生正确的比例，尤其是在工作时间很短的时候

步长调度里每个工作都有自己的步长，这个值与票数成反比。

例如，同样是分配彩票，用一个大数除以票数得到步长。每次进程运行后行程值（初始为0）增加步长，调度时根据步长及行程来确定调度哪个进程，优先调度最小行程的进程。

![image-20210714205502501](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210714205502.png)

> 但有一个问题，对于新加入的进程要如何设置步长？0的话会独占CPU
>
> 而抽奖调度并没有解决如何分配彩票的问题。
>
> 由于一些原因，最终这两个调度都没有被广泛使用

- 英文版这里介绍了CFS但是暂且放过他吧

## 作业

> 略

# 第十章 多处理器调度

> 等学完并发再看

------

# 第十三章 抽象：地址空间

早期的系统就是一个库，并没有提供多少抽象给用户。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210714222233.png" alt="image-20210714222233592" style="zoom:50%;" />

后来有了在IO时切换进程（多道程序），根据时间片交替执行程序（时分共享）。

## 地址空间

- 一个进程的地址空间包含运行的程序的所有内存状态

如果将进程简单的分为三部分要存储：代码，堆和栈

下图是一个地址分配的例子。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210714222340.png" alt="image-20210714222340858" style="zoom:50%;" />

虚拟化内存：操作系统为单一物理内存上的多个进程构建一个私有的地址空间

例如，进程A尝试在地址0操作时，实际上操作的是物理地址320KB。

> 如何隔离这些进程让他们不要访问到其他进程的内存是个要解决的问题

## 虚拟内存的目标

- 透明：进程可以像拥有真实地址空间一样操作虚拟地址
- 效率： 时间和空间
- 保护：保护进程之间不受干扰，也就是隔离

> 所以在代码中访问的地址都是虚拟地址...

# 第十四章 内存操作API

> UNIX操作系统内存分配接口

在运行C语言程序时，有两种类型的内存，第一种内存称为栈内存，由编译器管理申请和释放，也叫自动内存。

```c
void func(){
	int x;
}
```

如果要保存信息于函数作用域之外，需要使用堆内存，它的申请和释放由程序员显示完成。

```c
void func(){
int*x = (int*)malloc(sizeof(int));
}
```

> 呃本章主要介绍C语言的API不记了q

这些都是库而不是系统调用，但是内部实现包含系统调用

# 第十五章 机制：地址转换

## 基于硬件的地址交换

- 硬件对每次内存访问进行处理，诸如指令获取，数据读取或写入，将指令中的虚拟地址转换为数据实际存储的物理地址。每次内存引用时，硬件都会进行地址转换，将内存引用重定位到实际位置。

- 仅靠硬件是不够的，操作系统在关键位置介入，设置好硬件，因此操作系统必须管理内存记录占用和空闲位置，保持对内存的控制。

> 进程看来内存如下

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210715210107.png" alt="image-20210715210107866" style="zoom: 50%;" />

实际上

![image-20210715210043812](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210715210043.png)

### 动态（基于硬件）重定位

这种方式用到两个硬件寄存器，基址（base）寄存器和界限（bound）寄存器。操作系统决定加载物理地址在某处的进程，就将基址寄存器设为那个值，这时：

**物理地址 = 基地址 + 虚拟地址**

硬件将计算得出的真实地址发送给内存系统，就能找到实际位置来读取指令或者数据了（内存上没什么区别）。

> 学过汇编就马上明白这是怎么回事了，段寄存器<<16+地址值就能找到一个物理地址

由于这种重定位是在运行时发生的，而且进程开始后也可以改变其地址空间，这种技术一般被称为动态重定位。

界限寄存器的另一个作用是提供**访问保护**，如果进程要访问超出界限或为负数的地址，CPU将触发异常，进程可能被终止。

> CPU中的内存转换部分也被统称为内存管理单元MMU

### 硬件支持

![image-20210715212344015](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210715212344.png)

### 操作系统的职责

![image-20210715213051509](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210715213051.png)

> 如下是一个典型的运行过程

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210715213601.png" alt="image-20210715213601040" style="zoom:50%;" />

当前将内存分为定长的块，问题是有很多内部碎片（被分配但未使用的内存），效率不高。

# 第十六章 分段

## 分段：泛化的基址/界限

在MMU中引入多个基址和界限寄存器对，给地址空间内的每个逻辑段（栈段，代码段，堆段）一对寄存器。这样就可以让操作系统将不同的段放到不同的物理内存区域。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210716205437.png" alt="image-20210716205436763" style="zoom:50%;" />

举个例子

给定堆的虚拟地址，堆的基地址，需要先计算出虚拟地址的偏移量，就是相对于虚拟地址0的偏移，然后再用基地址+偏移量得出物理地址。

**引用哪个段？**

硬件在转换时使用段寄存器，如何得知段的偏移量和哪个段？

- 显式方式

一种方式是在虚拟地址的开头标识不同的段

![image-20210716210845556](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210716210845.png)

由于只有三个段而有一个段的地址空间被浪费，也有的操作系统把栈和堆当做同一个段，只用一位

- 隐式方式

硬件通过地址产生的方式来确定段，例如由PC产生的位于代码段，基于栈或基址指针，他一定在栈段，其他就是堆段。

## 栈

栈的地址空间反向增长，地址转换时硬件需要知道是否反向增长。

反向增长的地址需要用偏移量减去最大的段地址，得到反向（负的）偏移量。

## 支持共享

要节省内存，在地址空间共享某些内存段是有用的，尤其是代码段。

为了支持共享，同时防止破坏隔离性，需要硬件支持保护位。为每个段增加几个位标识程序是否能够读写或者执行其中的代码。这样就可以悄悄地共享内存。

![image-20210716213224560](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210716213224.png)

## 新的问题

- 新的地址空间被创建时，操作系统需要在物理内存中为它的段找到空间，这些段大小不一，这会导致一个问题

物理内存很快充满了许多空闲空间的小洞，因而很难分配给新的段，或者扩大已有的段。这被称为**外部碎片**。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210716213806.png" alt="image-20210716213806404" style="zoom:50%;" />

- 一种解决方式是紧凑物理内存，操作系统先终止运行的进程，将数据复制到连续的内存区域，改变段寄存器的值指向新的位置。但是这么做成本太高。
- 另一种做法是使用空闲列表管理算法，这种算法有很多，意在减少碎片，但是想要避免这个问题就永远不要分配不同大小的内存块。

# 第十七章 空闲空间管理

如果要管理的空间被划分为固定大小的单元，管理空间只需要一个列表，如果请求，返回列表中的一项即可。

如果要管理的空间由不同大小的单元构成，管理就变得困难（比如用户级的内存分配库malloc和free，系统的分段），这种情况下出现了**外部碎片**，后续的请求有可能失败，因为没有足够大的连续空间，计时总的空闲空间超出了请求大小。

C语言中一旦将堆中的空间分配给程序，因为无法追踪到所有引用，不能像分段那样紧凑空闲空间。

> 带gc的强类型语言情况有所不同

## 底层级制

### 分割与合并

- 空闲列表

![image-20210717200329155](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210717200329.png)

上面的情况，如果申请大于10字节的空间就会失败，如果小于10字节的话，系统就会找到一块满足请求的空间，进行分割，第一块给用户，剩下的留在空闲列表。

比如申请1字节

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210717201129.png" alt="image-20210717201129732" style="zoom:50%;" />

相对的，在程序归还空间时(free)，系统会进行合并，检查归还的块是否与原空闲块相邻，相邻就合并为一个更大的空闲块。

比如归还中间的10字节

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210717201344.png" alt="image-20210717201344576" style="zoom:50%;" />

### 追踪已分配空间的大小

> free(void *ptr)并没有块大小的参数，那么是如何确定要释放的空间大小呢？

大多数分配程序会在返回的内存块之前的**头块**里保存一些额外的信息，诸如分配空间大小和一个魔法数用来提供完整性检查。

```c
typedef struct header_t{
	int size;
	int magic;
} header_t;
```

而用户调用free时通过简单地指针运算得到头块的位置

```c
void free(void *ptr){
	header_t *hptr = (void *)ptr - sizeof(header_t);
}
```

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210717202433.png" alt="image-20210717202433860" style="zoom:50%;" />

实际释放的是头块大小加上分配给程序的空间。

### 嵌入空闲列表

> 在内存分配库里不能调用malloc分配空间，要如何在空闲空间建立空闲空间列表？

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210717213939.png" alt="image-20210717213939206" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210717213957.png" alt="image-20210717213957502" style="zoom:50%;" />

### 堆增长

> 如果堆空间耗尽要怎么办？

- 返回NULL表示分配失败
- 向系统申请更大的空间，比如调用sbrk，系统会找到空闲的物理内存页，映射到请求的进程地址空间去，并返回新的堆的末尾地址

## 基本策略

- 最优匹配

遍历空闲列表，寻找和请求大小一样或更大的空闲块，返回最小的那个。

- 最差匹配

找最大的空闲块，分割后将剩余的加入空闲列表，同样需要遍历列表。

- 首次匹配

找到首个足够大的块就返回。

- 下次匹配

每次从上次查找结束为止开始继续查找

## 其他方式

### 分离空闲列表

如果某个应用程序经常申请几种固定大小的内存空间，那就用一个单独的列表只管理这样大小的对象。其他请求交给更通用的内存分配程序。

好处是碎片问题解决了，分配释放也很快。

>  需要解决的问题是如何确定要分配多少内存给某种类型的对象？

### 伙伴系统

将地址看成大小为2的幂次方的空间，分配时空闲空间被递归的一分为二，直到刚好满足请求大小。

![image-20210717220903383](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210717220903.png)

会有内部碎片问题，但是在释放时，分配进程检查伙伴是否空闲，是就合并，递归的合并直到某个伙伴还没有释放。每对伙伴地址只有一位不同，也决定了在结构树中的层次。

> 上面介绍的方法缺乏扩展性，先进的分配程序会采用更复杂的数据结构来优化这个开销。

# 第十八章 分页：介绍

> 将空间分为定长的分片，在虚拟内存中称为「分页」

相应的，把物理内存看成是定长槽块的阵列，叫做页帧。每个页帧包含一个虚拟内存页。



<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210719213210.png" alt="image-20210719213210025" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210719213220.png" alt="image-20210719213220785" style="zoom:50%;" />

操作系统通常为每个进程保存了一个数据结构，称为**页表**（page table）。保存每个虚拟页面的地址转换，从而得知页在物理内存中的位置。大多数页表都是每个进程一份。

- 转换地址的例子

如果我们有一个64字节的小地址空间，需要总共6位地址表示如下

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210719214332.png" alt="image-20210719214332574" style="zoom:50%;" />

如果我们知道页的大小16字节，就可以进一步划分为**虚拟页**号（VPN）和**偏移量**。

页面大小16字节，位于64字节的地址空间，虚拟页号得知选择的页，偏移量则表示具体字节。

例如：
虚拟地址21转换为二进制 010101

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210719214719.png" alt="image-20210719214719248" style="zoom:50%;" />

虚拟地址21 在虚拟页01 的第5个字节处。通过虚拟页号可以检索页表来找到物理页号（PFN&PPN）用PFN替换VPN来转换虚拟地址。

可以发现偏移量不需要改变。

- 页表存在哪里

页表可以很大，每个进程的页表存储在内存中。

- 页表的内容

页表实现的最简单数据结构是一个数组也叫线性页表，通过VPN索引到页表项PTE。

PTE包含许多位来表示诸如有效位（是否可用），保护位，存在位（不常用的页可能被换到磁盘中），脏位等等。详情阅读对应的架构手册。

**当前的问题**

以下是从一个虚拟地址到读取内存中数据放入寄存器的过程

![image-20210719225019186](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210719225019.png)

- 太慢了
- 占用太多内存

# 第19章 分页：快速地址转换（TLB）

> 由于分页需要的映射信息存储在物理内存中，所以在转换虚拟地址时，都需要一次额外的内存访问。这太慢了。

想让操作系统更快，通常要求助于硬件的帮助。来让我们认识一下TLB。

## TLB

- 全名地址转换旁路缓冲存储器（translation-lookaside buffer)

- 对于每次内存访问，硬件先检查TLB，如果有期望的映射直接转换，不用访问页表（包含全部映射，在内存中）。
- TLB带来了巨大性能提升

## TLB基本算法

> 假定使用线性页表

![image-20210721220926016](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210721220926.png)

- 提取页号到TLB中检查，如果有VPN的转换映射则称为"TLB hit"，此时直接用偏移量和映射的PFN就可以访问物理地址了。
- 如果未命中则会到页表中查询，开销很大，应该尽量避免
- 如果页较大，而且空间时间局部性强，TLB命中率就会提高

> 谁来处理TLB未命中

答案可能有两个

- 硬件

以前有复杂指令集计算机CISC，硬件全权处理。

为此硬件必须知道页表在内存中的确切位置，发生未命中时，遍历页表找到正确的页表项，取出想要的页表项，更新TLB。

一个例子是x86架构，采用固定的多级页表，当前页表由CR3寄存器指出。

- 软件

更现代的精简指令集计算机RISC，当TLB未命中时硬件会抛出一个异常，和其他异常流程没什么区别，提升到内核模式陷入"trap"，这段代码处理TLB未命中。

![image-20210721222747252](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210721222747.png)

需要小心的是，这段程序要避免陷入递归的TLB未命中，一种解决方案是直接放到物理内存，不进行映射，或者在TLB中保留永久有效的一段地址。

这样更灵活，简单，硬件无需做太多，交给操作系统处理就好。

## TLB的内容

映射可能存在TLB中的任意位置，所以硬件并行的查找TLB。

![image-20210721223229701](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210721223229.png)

- TLB的有效位仅表示是否是有效的映射（被使用）
- 保护位，标识页的访问权限
- 空间标识符
- 脏位

## 上下文切换对TLB的处理

TLB中的项只对当前的进程有效，对其他进程没有意义，切换进程时，要确保不发生误读。

解决方案

1. 切换上下文时清空TLB

操作系统可以用一条特权指令来完成，硬件则可以在页表基址寄存器发生变化时将有效为置为0。

然而，每次进程运行都会触发未命中，如果操作系统频发切换进程，开销就会很大。

2. 空间标识符

有些系统在TLB中增加了空间标识符ASID，可以吧ASID看作是进程标识符，只需要用这个标识符区分进程就好。当然硬件也需要知道当前运行的进程ASID，一个特权寄存器存放这个ASID即可。

![image-20210721224401931](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210721224402.png)

## TLB替换策略

> 插入新项时要替换哪个？

- LRU 替换最近最少使用的项
- 随机

## 实际系统的TLB

![image-20210721224926688](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210721224926.png)

# 第二十章 分页：较小的表

> 如何让页表更小？

- 简单的办法

使用更大的页，就可以减少总页表的大小，然而这种方法会导致每页内的浪费（内部碎片）。

程序会分配页，但只用每页的一小部分，因此多系统都用较小的页，4KB或8KB。

## 分页和分段

在原来的每个进程的页表中有许多的空间被浪费，如下：

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210726203112.png" alt="image-20210726203111983" style="zoom:50%;" />

如果将分页和分段结合，就得到了一种新的方案。

我么不再为进程的整个地址空间提供单个页表，而是为每个逻辑分段提供一个。比如，为代码段，栈段，堆段分别提供页表，这样我们需要三对寄存器来保存三个页表的物理基地址和界限。

这样虚拟地址需要为确定用哪个段使用两位地址空间作为SN分段位，比如01代表代码段，10代表堆段之类的。

![image-20210726203557412](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210726203557.png)

TLB未命中时根据分段SN就可以确定寄存器，找到对应的页表。

![image-20210726203823004](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210726203823.png)

这种方案的优势在于很显著的节省了内存，堆和栈之间未分配的页不再占用页表空间。

但是，分段对地址空间的使用模式有要求，而且任意大小的页表使内存中寻找自由空间更复杂。

## 多级页表

多级页表将页表分成页大小的单元，如果整页没有有效项（PTE），就不分配该页的页表，也就是不在内存中保存。使用页目录来追踪页表是否有效，页目录可以得知页表的位置或者页表无效。

如下是例子，左侧是线性页表，右侧是多级页表

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210726204833.png" alt="image-20210726204833406" style="zoom:50%;" />

由于使用的内存由页目录管理，可以不用连续的空间。

但是在TLB未命中时需要加载两次内存，一次是页目录，一次是PTE。而且多级页表使查找变得复杂。

![image-20210726212512753](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210726212512.png)

![image-20210726212456581](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210726212456.png)

- 更多级

如果页目录太大，将目录本身拆分成多个页，再在其上添加另一个目录。

![image-20210726212159027](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210726212159.png)

## 反向页表

只用一个页表表示每个物理页，记录哪个进程的哪个虚拟页，使用更高效的数据结构加速查找。

> 页表只是数据结构，而上面只是几个例子

# 第二十一章 超越物理内存：机制

> 虚拟内存将提供超出物理内存的地址空间

## 交换空间

> 在硬盘上开辟一部分空间用于物理页的移入和移出

将物理内存中的也交换到硬盘上，需要时交换回去。

所以操作系统需要记录给定页的硬盘地址。 ![image-20210727194403663](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727194403.png)

> 注意，交换空间并不是唯一的硬盘交换目的地，从硬盘上加载代码之类的也需要读取硬盘

## 存在位

当硬件在PTE中查找时，可能发现页不在物理内存中。硬件判断是否在内存中的方法，是通过TLB中的存在位，访问不在物理内存中的页这种行为被称为「页错误」。

> 硬件不知道如何做时唯一能做的是触发异常，将控制交给操作系统，所以将这种行为叫做错误可能并不奇怪。

如果一个页不存在，处理页错误时操作系统可以通过PTE中的某些为来存储硬盘地址。向磁盘发送请求，读取页到内存中。之后更新PTE或者直接更新TLB和PTE。

处理页错误时I/O是阻塞的，此时操作系统可以自由运行其他的可执行程序。

![image-20210727201336959](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727201337.png)

- TLB未命中三种情况

1. 页存在且有效，直接到页表中获取即可，之后再次重试指令就会命中。
2. 页表有效但不存在，也错误处理程序执行，如果内存没有足够的空间还需要等待交换算法执行。
3. 不合法的页，引发异常，操作系统可能会杀死进程。

## 页交换算法

> 操作系统可以主动地预留一小部分空闲内存

为了保证有少量的空闲内存，大多数操作系统会设置高低水位线(HW&LW)来决定何时从内存中清除页。

当操作系统发现有少于LW个页可用时，后台负责释放内存的线程就会释放内存直到有HW个可用页。这个后台线程叫「页守护进程」。

# 第二十二章 超越物理内存：策略

> 可以将内存视为虚拟内存页的缓存

我们意图减少缓存未命中，衡量指标是：

- AMAT（平均内存访问时间）

**AMAT = （Phit * Tm）+(Pmiss * Td)**

Tm指内存访问时间，Td是硬盘访问时间，PMiss指未命中概率,Phit是命中概率

## 最优替换策略

- 替换最远将来才会被访问的页

这很不切实际，但是作为对比很有价值。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727210450.png" alt="image-20210727210450664" style="zoom:50%;" />

> 未命中有时会被分为三类：强制性，容量，冲突

## FIFO

> 先进先出

![image-20210727210926446](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727210926.png)

## 随机

> 就随机...实现简单，性能看运气

![image-20210727211137271](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727211137.png)

## LRU

> 替换掉最近最不常用的

![image-20210727211957515](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727211957.png)

- 当工作负载不存在局部性时这些策略差不多

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727212217.png" alt="image-20210727212217486" style="zoom:50%;" />

- 在80%的引用20%的页时

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727212253.png" alt="image-20210727212253346" style="zoom:50%;" />

- 循环顺序

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727214114.png" alt="image-20210727214114859" style="zoom:50%;" />

## 近似LRU

> 找到最旧的页开销巨大，如果维护一个时间字段，并在每次都找最旧的话
>
> 找个差不多的行不行？

比如在每个页有一个使用位，硬件在引用页时将页的使用位设为1。

操作系统则使用一个时钟指针指向某个页，当需要替换时按顺序检查使用位，如果是1置为0，如果是0则说明最近没有使用这个页，就可以替换。

<img src="https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727214655.png" alt="image-20210727214655617" style="zoom:50%;" />

## 脏页

如果页被修改（变脏），将他写回磁盘成本很高，如果没被修改，就可以直接重用而没有成本。

因此一些系统更倾向于替换干净的页，为此可能硬件需要提供一个修改位。

- 其他一些策略：决定何时写入内存的页选择策略，如何写入磁盘的聚集写入或者分组写入策略等等

## 抖动

如果内存被超额请求，系统将不断地进行换页，这被称为「抖动」。

为了避免抖动，系统可能会决定不运行某些进程，称为「准入控制」。

或者直接杀死某些内存密集型进程。

# 第二十三章 VAX/VMS虚拟内存系统

![image-20210727225014142](https://raw.githubusercontent.com/C1EYE/figureBed/main/img/20210727225014.png)

- 写时复制
- 按需读取

